{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AAvYHJDSm7u",
        "outputId": "1858cb52-2d20-4b69-fb55-f51b515b138b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T_quWI3ZSrxa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB-kBEG6BPAG",
        "outputId": "07d2b415-3d2d-4e7b-9f21-f26fee4777c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "6ZdzyyspS75h",
        "outputId": "f86eb8e6-d363-4ef8-f0a6-6b9dd00d5c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33cd75d5-14b6-4f9d-9f19-29ec325dcdc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
              "      <td>Melissa Jeltsen</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
              "      <td>She left her husband. He killed their children...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>Of course it has a song.</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
              "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
              "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33cd75d5-14b6-4f9d-9f19-29ec325dcdc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33cd75d5-14b6-4f9d-9f19-29ec325dcdc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33cd75d5-14b6-4f9d-9f19-29ec325dcdc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        category  ...       date\n",
              "0          CRIME  ... 2018-05-26\n",
              "1  ENTERTAINMENT  ... 2018-05-26\n",
              "2  ENTERTAINMENT  ... 2018-05-26\n",
              "3  ENTERTAINMENT  ... 2018-05-26\n",
              "4  ENTERTAINMENT  ... 2018-05-26\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "filename = \"/content/drive/MyDrive/SDLC/news_analysis_project/data/final_news_category_dataset.json\"\n",
        "df = pd.read_json(filename, orient='split')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "lv6Q_YkCS_6o",
        "outputId": "934b4f30-935a-4f7b-c0b7-bba49f35093f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-674f0602-7b42-4338-a2e4-5c723e1a73f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>Of course it has a song.</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
              "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
              "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/morgan-fr...</td>\n",
              "      <td>\"It is not right to equate horrific incidents ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200800</th>\n",
              "      <td>WELLNESS</td>\n",
              "      <td>The Sleep Library: 11 Soothing Books For Bedtime</td>\n",
              "      <td></td>\n",
              "      <td>https://www.huffingtonpost.comhttp://www.oprah...</td>\n",
              "      <td>Do you toss and turn until you finally sit up ...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200802</th>\n",
              "      <td>WELLNESS</td>\n",
              "      <td>The Benefits of Caring for a Pet</td>\n",
              "      <td>Rita Altman, R.N., Contributor\\nSenior Vice Pr...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/pets-seni...</td>\n",
              "      <td>For the young as well as the old, especially i...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200805</th>\n",
              "      <td>WELLNESS</td>\n",
              "      <td>This Is Only the Beginning: Surprising Advice ...</td>\n",
              "      <td>Ellie Knaus, Contributor\\nAtomic Moms Podcast ...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/life-tips...</td>\n",
              "      <td>My great-aunt Ida loves to say, \"This is only ...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200838</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Sundance, Ice-T, and Shades of the American Ra...</td>\n",
              "      <td>Courtney Garcia, Contributor\\nI tell stories a...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/sundance-...</td>\n",
              "      <td>Representation of the collective diaspora has ...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200839</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>'Girl With the Dragon Tattoo' India Release Ca...</td>\n",
              "      <td></td>\n",
              "      <td>https://www.huffingtonpost.com/entry/girl-with...</td>\n",
              "      <td>\"Sony Pictures will not be releasing The Girl ...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66624 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-674f0602-7b42-4338-a2e4-5c723e1a73f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-674f0602-7b42-4338-a2e4-5c723e1a73f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-674f0602-7b42-4338-a2e4-5c723e1a73f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             category  ...       date\n",
              "1       ENTERTAINMENT  ... 2018-05-26\n",
              "2       ENTERTAINMENT  ... 2018-05-26\n",
              "3       ENTERTAINMENT  ... 2018-05-26\n",
              "4       ENTERTAINMENT  ... 2018-05-26\n",
              "5       ENTERTAINMENT  ... 2018-05-26\n",
              "...               ...  ...        ...\n",
              "200800       WELLNESS  ... 2012-01-28\n",
              "200802       WELLNESS  ... 2012-01-28\n",
              "200805       WELLNESS  ... 2012-01-28\n",
              "200838  ENTERTAINMENT  ... 2012-01-28\n",
              "200839  ENTERTAINMENT  ... 2012-01-28\n",
              "\n",
              "[66624 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_3 = df[df.category.isin(df.category.value_counts()[:3].index.values)]\n",
        "df_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBZJJ3jQDQZr"
      },
      "source": [
        "# Finding the ratio between the number samples to an average words in a sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M0hGdLeGUwO"
      },
      "source": [
        "The above ratio being above 1500 signals that one should use a sequence model while less than 1500 means that bag-of-ngrams should work better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "waKRknvwDPxA"
      },
      "outputs": [],
      "source": [
        "def find_ratio(df):\n",
        "    col = 'short_description'\n",
        "    return len(df)/df[col].apply(lambda x: len([j.translate(str.maketrans('', '', string.punctuation)) for i in x.split('.') for j in i.split()])).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62LA739lDb5f",
        "outputId": "c2666a81-e740-4fd3-c72c-e0428b385bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 8.58 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10123.495628334394"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "%time\n",
        "find_ratio(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixjvh9cSG1IF",
        "outputId": "179fa45e-176a-4697-93d3-574277bec16e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3490.620950847106"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "find_ratio(df_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vXQrZD1G4wq"
      },
      "source": [
        "As we can see, it is much better to go for a sequence model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2pmmpUgwTD-m"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = df_3['category'].astype('category').cat.codes\n",
        "y_encoded = keras.utils.to_categorical(y)\n",
        "\n",
        "\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(df_3['short_description'], y_encoded, test_size=0.2, stratify=y, random_state=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X47lgaZvJsN2"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        (\n",
        "            tf.cast(sentences_train.values, tf.string),\n",
        "            y_train\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        (\n",
        "          tf.cast(sentences_test.values, tf.string),\n",
        "          y_test\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "test_ds = test_ds.batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3mxjzIoVQWv"
      },
      "source": [
        "# Simple model on unigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nPjDFYQ-Cp6Y"
      },
      "outputs": [],
      "source": [
        "text_vectorization = keras.layers.TextVectorization(\n",
        "        max_tokens=20000,\n",
        "        output_mode=\"multi_hot\",\n",
        ")\n",
        "\n",
        "def custom_standardization_fn(string_tensor): \n",
        "    lowercase_string = tf.strings.lower(string_tensor) \n",
        "    return tf.strings.regex_replace(lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VKa7FUMJMSI6"
      },
      "outputs": [],
      "source": [
        "text_only_train_ds = train_ds.map(lambda x, y: x) \n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=-1)\n",
        "\n",
        "binary_1gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-nTcF-oMr54",
        "outputId": "54834c98-7f01-4782-f99b-44492162beb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'float32'>\n",
            "targets.shape: (32, 3)\n",
            "targets.dtype: <dtype: 'float32'>\n",
            "inputs[0]: tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]], shape=(32, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "  print(\"inputs.shape:\", inputs.shape)\n",
        "  print(\"inputs.dtype:\", inputs.dtype)\n",
        "  print(\"targets.shape:\", targets.shape)\n",
        "  print(\"targets.dtype:\", targets.dtype)\n",
        "  print(\"inputs[0]:\", inputs[0])\n",
        "  print(targets)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KujNEVBNNAxh"
      },
      "outputs": [],
      "source": [
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = keras.layers.Dense(hidden_dim, activation=\"relu\")(inputs) \n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "    outputs = keras.layers.Dense(3, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs, outputs) \n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                    loss=\"categorical_crossentropy\",\n",
        "                    metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vkt4rvCNR6T",
        "outputId": "f44b0b2f-b692-45cf-e9dd-7420b43b521c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,067\n",
            "Trainable params: 320,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1666/1666 [==============================] - 14s 6ms/step - loss: 0.6490 - accuracy: 0.7236\n",
            "Epoch 2/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.5160 - accuracy: 0.7861\n",
            "Epoch 3/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4936 - accuracy: 0.7969\n",
            "Epoch 4/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4917 - accuracy: 0.8019\n",
            "Epoch 5/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4856 - accuracy: 0.8070\n",
            "Epoch 6/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4769 - accuracy: 0.8066\n",
            "Epoch 7/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4793 - accuracy: 0.8098\n",
            "Epoch 8/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4805 - accuracy: 0.8125\n",
            "Epoch 9/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4716 - accuracy: 0.8135\n",
            "Epoch 10/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4732 - accuracy: 0.8135\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4427 - accuracy: 0.8241\n",
            "Test acc: 0.824\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          epochs=10\n",
        ")\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss2j34iSQ_Ja"
      },
      "source": [
        "# Simple model on bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "25a3sDWNR4gU"
      },
      "outputs": [],
      "source": [
        "text_vectorization_bigrams = keras.layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FfAHF6E_R8g0"
      },
      "outputs": [],
      "source": [
        "text_vectorization_bigrams.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(lambda x, y: (text_vectorization_bigrams(x), y), num_parallel_calls=-1)\n",
        "binary_2gram_test_ds = test_ds.map(lambda x, y: (text_vectorization_bigrams(x), y), num_parallel_calls=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2OTZgLKSTe6",
        "outputId": "4875f7dd-41a4-428d-9c73-cf8baaf47fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,067\n",
            "Trainable params: 320,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1666/1666 [==============================] - 10s 5ms/step - loss: 0.6396 - accuracy: 0.7223\n",
            "Epoch 2/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.5089 - accuracy: 0.7923\n",
            "Epoch 3/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4874 - accuracy: 0.8058\n",
            "Epoch 4/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4798 - accuracy: 0.8104\n",
            "Epoch 5/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4636 - accuracy: 0.8181\n",
            "Epoch 6/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4685 - accuracy: 0.8160\n",
            "Epoch 7/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4578 - accuracy: 0.8211\n",
            "Epoch 8/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4569 - accuracy: 0.8217\n",
            "Epoch 9/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4601 - accuracy: 0.8206\n",
            "Epoch 10/10\n",
            "1666/1666 [==============================] - 8s 5ms/step - loss: 0.4527 - accuracy: 0.8228\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4614 - accuracy: 0.8170\n",
            "Test acc: 0.817\n"
          ]
        }
      ],
      "source": [
        "model_bigrams = get_model()\n",
        "model_bigrams.summary()\n",
        "\n",
        "model_bigrams.fit(binary_2gram_train_ds.cache(),\n",
        "          epochs=10\n",
        ")\n",
        "\n",
        "print(f\"Test acc: {model_bigrams.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNZKb4MG9_Z7"
      },
      "source": [
        "# Model with LSTM layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "16SY_B_fPaAA"
      },
      "outputs": [],
      "source": [
        "tokenizer_raw = keras.preprocessing.text.Tokenizer(num_words=60000)\n",
        "tokenizer_raw.fit_on_texts(sentences_train)\n",
        "\n",
        "X_train_raw = tokenizer_raw.texts_to_sequences(sentences_train)\n",
        "X_test_raw = tokenizer_raw.texts_to_sequences(sentences_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S7I9f3YzPgA0"
      },
      "outputs": [],
      "source": [
        "vocab_size_raw = len(tokenizer_raw.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lGuf7nQNPjTn"
      },
      "outputs": [],
      "source": [
        "maxlen_raw = 100\n",
        "\n",
        "X_train_raw = keras.preprocessing.sequence.pad_sequences(X_train_raw, padding='post', maxlen=maxlen_raw)\n",
        "X_test_raw = keras.preprocessing.sequence.pad_sequences(X_test_raw, padding='post', maxlen=maxlen_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-NzTT_8VGrm"
      },
      "source": [
        "## Building a model with a pretrained embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUpAQYdTVKKM",
        "outputId": "5e31232b-55e2-4929-edd5-22e3712476c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-19 19:42:19--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-02-19 19:42:19--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-02-19 19:42:19--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 40s  \n",
            "\n",
            "2022-02-19 19:44:59 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9QVfOJ4VLb4",
        "outputId": "c666b10a-ab58-42f8-fe26-a00f41632144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.04445\n"
          ]
        }
      ],
      "source": [
        "!head -n 1 glove.6B.50d.txt | cut -c-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2XnRPA0SVPA2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix_raw = create_embedding_matrix('glove.6B.100d.txt', \n",
        "                                               tokenizer_raw.word_index,\n",
        "                                               embedding_dim)    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model with single UniDirectional LSTM layer"
      ],
      "metadata": {
        "id": "epbYb0xBUVUa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P52YgHAOPwui"
      },
      "outputs": [],
      "source": [
        "model_simple_lstm = keras.models.Sequential()\n",
        "model_simple_lstm.add(keras.layers.Embedding(vocab_size_raw, embedding_dim, weights=[embedding_matrix_raw], input_length=maxlen_raw, trainable=False))\n",
        "model_simple_lstm.add(keras.layers.LSTM(maxlen_raw))\n",
        "model_simple_lstm.add(keras.layers.Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xRK1mCRiT_nS"
      },
      "outputs": [],
      "source": [
        "# opt = keras.optimizers.RMSprop()\n",
        "opt = keras.optimizers.Adam()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_lstm.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2V_F0grAVyDj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIQZQVCtTX9F",
        "outputId": "94501c47-4bfd-4a5f-c216-4956bbdb952c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          4053900   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,134,603\n",
            "Trainable params: 80,703\n",
            "Non-trainable params: 4,053,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_simple_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v640Ev3rToAa"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "             keras.callbacks.EarlyStopping(patience=3)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AgWKh7GTfzd",
        "outputId": "072c7351-656f-4a78-dfa1-6ea3d5fa746e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 53s 27ms/step - loss: 0.8145 - accuracy: 0.6251 - val_loss: 0.6027 - val_accuracy: 0.7350\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 45s 27ms/step - loss: 0.5653 - accuracy: 0.7528 - val_loss: 0.5153 - val_accuracy: 0.7930\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 46s 28ms/step - loss: 0.4732 - accuracy: 0.8092 - val_loss: 0.4474 - val_accuracy: 0.8146\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 45s 27ms/step - loss: 0.4809 - accuracy: 0.7975 - val_loss: 0.4622 - val_accuracy: 0.7903\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 45s 27ms/step - loss: 0.3974 - accuracy: 0.8274 - val_loss: 0.3973 - val_accuracy: 0.8312\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 45s 27ms/step - loss: 0.4364 - accuracy: 0.8105 - val_loss: 0.4168 - val_accuracy: 0.8259\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 44s 27ms/step - loss: 0.3788 - accuracy: 0.8364 - val_loss: 0.4666 - val_accuracy: 0.7914\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 44s 27ms/step - loss: 0.3669 - accuracy: 0.8392 - val_loss: 0.3757 - val_accuracy: 0.8366\n",
            "Epoch 9/30\n",
            "1666/1666 [==============================] - 44s 27ms/step - loss: 0.3479 - accuracy: 0.8466 - val_loss: 0.3710 - val_accuracy: 0.8377\n",
            "Epoch 10/30\n",
            "1666/1666 [==============================] - 44s 27ms/step - loss: 0.3831 - accuracy: 0.8361 - val_loss: 0.3803 - val_accuracy: 0.8332\n",
            "Epoch 11/30\n",
            "1666/1666 [==============================] - 46s 28ms/step - loss: 0.3540 - accuracy: 0.8473 - val_loss: 0.3836 - val_accuracy: 0.8330\n",
            "Epoch 12/30\n",
            "1666/1666 [==============================] - 46s 28ms/step - loss: 0.3400 - accuracy: 0.8506 - val_loss: 0.3958 - val_accuracy: 0.8247\n",
            "Training Accuracy: 0.8430\n",
            "Testing Accuracy:  0.8247\n"
          ]
        }
      ],
      "source": [
        "history_raw = model_simple_lstm.fit(X_train_raw, y_train,\n",
        "                    epochs=30,\n",
        "                    validation_data=(X_test_raw, y_test), callbacks=callbacks, batch_size=32)\n",
        "loss_training_raw, accuracy_training_raw = model_simple_lstm.evaluate(X_train_raw, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy_training_raw))\n",
        "loss_test_raw, accuracy_test_raw = model_simple_lstm.evaluate(X_test_raw, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy_test_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with single BiDirectional LSTM Layer and Embedding dim set to 100"
      ],
      "metadata": {
        "id": "bqaS2DpcUeLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N8d9wR3sT5rW"
      },
      "outputs": [],
      "source": [
        "model_simple_bilstm = keras.models.Sequential()\n",
        "model_simple_bilstm.add(keras.layers.Embedding(vocab_size_raw, embedding_dim, weights=[embedding_matrix_raw], input_length=maxlen_raw, trainable=False))\n",
        "model_simple_bilstm.add(keras.layers.Bidirectional(keras.layers.LSTM(maxlen_raw)))\n",
        "model_simple_bilstm.add(keras.layers.Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_bilstm.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.RMSprop(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "X0AkD5XIVtG1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_simple_bilstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppIHPKgoV3Rs",
        "outputId": "df0410b7-f5c6-43d7-ad9d-d511dacfb4b9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          4053900   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 200)              160800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 603       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,215,303\n",
            "Trainable params: 161,403\n",
            "Non-trainable params: 4,053,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_raw_bilstm = model_simple_bilstm.fit(X_train_raw, y_train,\n",
        "                    epochs=30,\n",
        "                    validation_data=(X_test_raw, y_test), callbacks=callbacks, batch_size=32)\n",
        "loss_training_raw_bilstm, accuracy_training_raw_bilstm = model_simple_bilstm.evaluate(X_train_raw, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy_training_raw_bilstm))\n",
        "loss_test_raw_bilstm, accuracy_test_raw_bilstm = model_simple_bilstm.evaluate(X_test_raw, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy_test_raw_bilstm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC2qBEEZV7RN",
        "outputId": "4e53de87-c7e2-4690-83db-a8fcd377df38"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 29s 13ms/step - loss: 0.4321 - accuracy: 0.8081 - val_loss: 0.3834 - val_accuracy: 0.8233\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 21s 12ms/step - loss: 0.3619 - accuracy: 0.8385 - val_loss: 0.3714 - val_accuracy: 0.8333\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 21s 12ms/step - loss: 0.3451 - accuracy: 0.8485 - val_loss: 0.3655 - val_accuracy: 0.8372\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 22s 13ms/step - loss: 0.3204 - accuracy: 0.8556 - val_loss: 0.3703 - val_accuracy: 0.8301\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 22s 13ms/step - loss: 0.3062 - accuracy: 0.8622 - val_loss: 0.3610 - val_accuracy: 0.8428\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 22s 13ms/step - loss: 0.2917 - accuracy: 0.8682 - val_loss: 0.3667 - val_accuracy: 0.8423\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.2707 - accuracy: 0.8770 - val_loss: 0.4047 - val_accuracy: 0.8332\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 22s 13ms/step - loss: 0.2517 - accuracy: 0.8839 - val_loss: 0.3940 - val_accuracy: 0.8422\n",
            "Training Accuracy: 0.8976\n",
            "Testing Accuracy:  0.8422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model with a single BiDirectional LSTM layer and another dense layer"
      ],
      "metadata": {
        "id": "z7vqKFsIhj2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bilstm = keras.models.Sequential()\n",
        "model_bilstm.add(keras.layers.Embedding(vocab_size_raw, embedding_dim, weights=[embedding_matrix_raw], input_length=maxlen_raw, trainable=False))\n",
        "model_bilstm.add(keras.layers.Bidirectional(keras.layers.LSTM(maxlen_raw)))\n",
        "model_bilstm.add(keras.layers.Dense(50, activation='relu'))\n",
        "model_bilstm.add(keras.layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "7OXvq5hiWPEn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bilstm.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.RMSprop(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Dx7V9y4YjonD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bilstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xTyHEhFjsYK",
        "outputId": "4e401dee-750a-4912-c0bd-86ea8dd675dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          4053900   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 200)              160800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 153       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,224,903\n",
            "Trainable params: 171,003\n",
            "Non-trainable params: 4,053,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_bilstm = model_bilstm.fit(X_train_raw, y_train,\n",
        "                    epochs=30,\n",
        "                    validation_data=(X_test_raw, y_test), callbacks=callbacks, batch_size=32)\n",
        "loss_training_bilstm, accuracy_training_bilstm = model_bilstm.evaluate(X_train_raw, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy_training_raw_bilstm))\n",
        "loss_test_bilstm, accuracy_test_bilstm = model_bilstm.evaluate(X_test_raw, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy_test_bilstm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv3Iumhvju_G",
        "outputId": "ccc97b59-d266-4f07-b4e9-6ac9d2928f00"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 28s 13ms/step - loss: 0.4295 - accuracy: 0.8080 - val_loss: 0.4962 - val_accuracy: 0.7911\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.3617 - accuracy: 0.8385 - val_loss: 0.3843 - val_accuracy: 0.8309\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.3392 - accuracy: 0.8481 - val_loss: 0.4242 - val_accuracy: 0.8292\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.3245 - accuracy: 0.8558 - val_loss: 0.3784 - val_accuracy: 0.8408\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 22s 13ms/step - loss: 0.3014 - accuracy: 0.8648 - val_loss: 0.3966 - val_accuracy: 0.8366\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.2892 - accuracy: 0.8707 - val_loss: 0.3771 - val_accuracy: 0.8408\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.2629 - accuracy: 0.8802 - val_loss: 0.4135 - val_accuracy: 0.8330\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.2432 - accuracy: 0.8881 - val_loss: 0.4461 - val_accuracy: 0.8368\n",
            "Epoch 9/30\n",
            "1666/1666 [==============================] - 21s 13ms/step - loss: 0.2241 - accuracy: 0.8950 - val_loss: 0.4971 - val_accuracy: 0.8370\n",
            "Training Accuracy: 0.8976\n",
            "Testing Accuracy:  0.8370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eCrTT1fvj9VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking the performance on entire dataset, with all (41) categories"
      ],
      "metadata": {
        "id": "o8Cme4Dlk1vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size_raw, embedding_dim, weights=[embedding_matrix_raw], input_length=maxlen_raw, trainable=False))\n",
        "model.add(keras.layers.Bidirectional(keras.layers.LSTM(maxlen_raw)))\n",
        "model.add(keras.layers.Dense(82, activation='relu'))\n",
        "model.add(keras.layers.Dense(41, activation='softmax'))"
      ],
      "metadata": {
        "id": "0WJzdYWdk5sW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting into train/test datasets"
      ],
      "metadata": {
        "id": "VWNWY02zlcO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_full = df['category'].astype('category').cat.codes\n",
        "y_encoded_full = keras.utils.to_categorical(y_full)\n",
        "\n",
        "\n",
        "sentences_train_full, sentences_test_full, y_train_full, y_test_full = train_test_split(df['short_description'], y_encoded_full, test_size=0.2, stratify=df['category'], random_state=1000)"
      ],
      "metadata": {
        "id": "_S1OpxHXlK7b"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Finding the number of unique words in the short_description column: \")\n",
        "words_set = set()\n",
        "for article in df['short_description'].values:\n",
        "    for sentence in article.split('.'):\n",
        "        for word in sentence.split(' '):\n",
        "            word = \"\".join([i for i in word if i.isalpha() or i.isspace()]).lower()\n",
        "            if word:\n",
        "                words_set.add(word)\n",
        "\n",
        "print(len(words_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcDEoz3bmLJ3",
        "outputId": "17cbc892-01da-41eb-c2b0-d4c8d37cdb5c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding the number of unique words in the short_description column: \n",
            "90376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=80000)\n",
        "tokenizer.fit_on_texts(sentences_train_full)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train_full)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test_full)"
      ],
      "metadata": {
        "id": "BEai5NolmCE_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen_raw = 100\n",
        "\n",
        "X_train = keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen_raw)\n",
        "X_test = keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen_raw)"
      ],
      "metadata": {
        "id": "piPZJKzqoKx4"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.RMSprop(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hLrsqUwKleS6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb-ahw9Dltp8",
        "outputId": "f0a21068-a112-42e2-f675-010b67c91631"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          4053900   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 200)              160800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 82)                16482     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 41)                3403      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,234,585\n",
            "Trainable params: 180,685\n",
            "Non-trainable params: 4,053,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train_full,\n",
        "                    epochs=40,\n",
        "                    validation_data=(X_test, y_test_full), callbacks=callbacks, batch_size=32)\n",
        "loss_training, accuracy_training = model.evaluate(X_train, y_train_full, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy_training))\n",
        "loss_test, accuracy_test = model.evaluate(X_test, y_test_full, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O59Yljsl0-H",
        "outputId": "bd262b6d-ae4b-485c-e77a-46218a0ff355"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "5022/5022 [==============================] - 72s 13ms/step - loss: 2.9436 - accuracy: 0.2267 - val_loss: 2.8633 - val_accuracy: 0.2507\n",
            "Epoch 2/40\n",
            "5022/5022 [==============================] - 65s 13ms/step - loss: 2.7673 - accuracy: 0.2723 - val_loss: 2.8514 - val_accuracy: 0.2689\n",
            "Epoch 3/40\n",
            "5022/5022 [==============================] - 64s 13ms/step - loss: 2.6516 - accuracy: 0.3030 - val_loss: 2.6784 - val_accuracy: 0.3067\n",
            "Epoch 4/40\n",
            "5022/5022 [==============================] - 65s 13ms/step - loss: 2.5766 - accuracy: 0.3228 - val_loss: 2.6086 - val_accuracy: 0.3193\n",
            "Epoch 5/40\n",
            "5022/5022 [==============================] - 65s 13ms/step - loss: 2.5320 - accuracy: 0.3339 - val_loss: 2.6810 - val_accuracy: 0.3213\n",
            "Epoch 6/40\n",
            "5022/5022 [==============================] - 64s 13ms/step - loss: 2.4998 - accuracy: 0.3422 - val_loss: 2.6564 - val_accuracy: 0.3062\n",
            "Epoch 7/40\n",
            "5022/5022 [==============================] - 64s 13ms/step - loss: 2.4720 - accuracy: 0.3473 - val_loss: 2.6409 - val_accuracy: 0.3256\n",
            "Training Accuracy: 0.3563\n",
            "Testing Accuracy:  0.3256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B_KDkfG6olHC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "checking_keras_examples&lstm.ipynb",
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}