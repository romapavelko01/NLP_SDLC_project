{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romapavelko01/NLP_SDLC_project/blob/classifications/classification_MB_for_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_8G-lIhmGBs",
        "outputId": "4ebe1a5e-c536-486c-f2ed-52e9d088e33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEsB14y_mOK1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "zmaixbKHmuOi",
        "outputId": "9d19cfd5-6d97-474c-ccfc-e67cf4bce66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
              "      <td>Melissa Jeltsen</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
              "      <td>She left her husband. He killed their children...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>Of course it has a song.</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category  ...       date\n",
              "0          CRIME  ... 2018-05-26\n",
              "1  ENTERTAINMENT  ... 2018-05-26\n",
              "2  ENTERTAINMENT  ... 2018-05-26\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename = \"/content/drive/MyDrive/SDLC/news_analysis_project/data/final_news_category_dataset.json\"\n",
        "df = pd.read_json(filename, orient='split')\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le9TTNODwvNe"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrB6es7RyBBn",
        "outputId": "60e73bcc-7984-4ba1-dac6-785cad003c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgSI8Snhw0pP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "def cleaning_function(sentence):\n",
        "    \"\"\"\n",
        "    Function needed to perform data preprocessing: removing punctuation symbols,\n",
        "    stop_words and other random things in order to obtain clean text\n",
        "    \"\"\"\n",
        "    # the following line removes numbers from text\n",
        "    result = re.sub(r'\\d+', '', sentence.lower())\n",
        "\n",
        "    # the following line removes any punctuation from the text\n",
        "    result = result.translate(str.maketrans('','',string.punctuation))\n",
        "    return [word for word in result.split() if not word in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tBI-2pkDx4hl",
        "outputId": "27c483fb-867b-4257-8d8a-c1161fc87b56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>processed_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>left husband killed children another day america</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>course song</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>actor longtime girlfriend anna eberstein tied ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>actor gives dems asskicking fighting hard enou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>dietland actress said using bags really cathar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                              processed_description\n",
              "0          CRIME   left husband killed children another day america\n",
              "1  ENTERTAINMENT                                        course song\n",
              "2  ENTERTAINMENT  actor longtime girlfriend anna eberstein tied ...\n",
              "3  ENTERTAINMENT  actor gives dems asskicking fighting hard enou...\n",
              "4  ENTERTAINMENT  dietland actress said using bags really cathar..."
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_1 = df.copy()\n",
        "df_1['processed_description'] = df_1['short_description'].apply(lambda x: ' '.join(cleaning_function(x)))\n",
        "df_1 = df_1[['category', 'processed_description']]\n",
        "df_1.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "junJXJDA7eqj"
      },
      "source": [
        "Let's check how many  (roughly, only lowercase) unique words are there in the datasets - processed and raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG-bflPb2Tb7",
        "outputId": "5fb0c8bc-3270-49cc-8bb4-80e8a68c5425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of words in the pre-processed dataset:  95150\n",
            "Total number of words in the raw dataset:  208227\n"
          ]
        }
      ],
      "source": [
        "all_words_processed = set(np.concatenate((*df_1.processed_description.apply(lambda x: x.split()).values,)))\n",
        "all_words_raw = set(np.concatenate((*df.short_description.apply(lambda x: x.split()).values,)))\n",
        "print(\"Total number of words in the pre-processed dataset: \", len(all_words_processed))\n",
        "print(\"Total number of words in the raw dataset: \", len(all_words_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1mmHH_moY6R"
      },
      "source": [
        "# Splitting data into train-test with train and test having the same distribution of news categorically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xc3JHiEojiP"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_1.processed_description, df_1['category'], \n",
        "                                                    test_size=0.2, stratify=df_1.category,\n",
        "                                                    random_state=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnhJnronxEa"
      },
      "source": [
        "# Model, making classifications based on short description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ7CeplG8QdI"
      },
      "source": [
        "## Creating a dataframe to store train and test accuracies of each combination of **vectorizer + (unigrams/bigrams/unigrams&bigrams) + classifier (in this case, MultinomialNB)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u9r-EFb8qmo"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(columns=['Classifier', 'By', 'Preprocessed', 'Vectorizer', 'Ngram', 'TopKFeatures', 'TrainAccuracy', 'TestAccuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FKPJmd39LVT"
      },
      "source": [
        "Creating a function to display and record results to the accuracies dataframe for each combination "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOxlVI1R9aL7"
      },
      "outputs": [],
      "source": [
        "def write_df(dataset, preprocessed, by, clf, vect, ngram=(1, 1), topk=6000, display=True):\n",
        "    \"\"\"\n",
        "    Function to calculate accuracies for the given dataset split, \n",
        "    whether it is raw or preprocessed; \n",
        "    by - in ['headline', 'descirption', 'full_text']\n",
        "    classifier, \n",
        "    vectorizer, ngram parameter, and how many top features to consider;\n",
        "    record calculated accuracies to the results_df;\n",
        "    and, once display is set to True, print classification accuracies\n",
        "    \"\"\"\n",
        "    global results_df\n",
        "\n",
        "    X_train, X_test, y_train, y_test = dataset\n",
        "\n",
        "    vectorizer = vect(ngram_range=ngram)\n",
        "    x_train_ = vectorizer.fit_transform(X_train)\n",
        "\n",
        "    # Vectorize validation texts.\n",
        "    x_val = vectorizer.transform(X_test)\n",
        "    # Select top 'k' of the vectorized features.\n",
        "    selector = SelectKBest(f_classif, k=min(topk, x_train_.shape[1]))\n",
        "    selector.fit(x_train_, y_train)\n",
        "    x_train = selector.transform(x_train_).astype('float32')\n",
        "    x_val = selector.transform(x_val).astype('float32')   \n",
        "\n",
        "    clf = clf()\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred_test = clf.predict(x_val)\n",
        "    y_pred_train = clf.predict(x_train)\n",
        "    train_acc, test_acc = accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)\n",
        "    if display:\n",
        "        print(f\"Train classification accuracy = {train_acc},\\n Test classification accuracy = {test_acc}\")\n",
        "\n",
        "    results_df = results_df.append(pd.DataFrame({\n",
        "        'Classifier': [clf.__class__.__name__],\n",
        "        'By': [by],\n",
        "        'Preprocessed': [preprocessed],\n",
        "        'Vectorizer': [vectorizer.__class__.__name__],\n",
        "        'Ngram': [ngram],\n",
        "        'TopKFeatures': [topk],\n",
        "        'TrainAccuracy': [train_acc],\n",
        "        'TestAccuracy': [test_acc]\n",
        "    }), ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpliSz8IA4I-"
      },
      "outputs": [],
      "source": [
        "raw_dataset_sh_ = train_test_split(df.short_description, df['category'], \n",
        "                                                    test_size=0.2, stratify=df.category,\n",
        "                                                    random_state=1)\n",
        "processed_split = (X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF3GMR2kodgD"
      },
      "source": [
        "## Without over/under-sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywvln9z-B5LU"
      },
      "outputs": [],
      "source": [
        "TOP_KS = np.arange(5000, 15000, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOxBXnYnB3ew"
      },
      "source": [
        "### Training on preprocessed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKTIw-2yOqc8"
      },
      "source": [
        "#### Using CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjBXlzguAWGm"
      },
      "source": [
        "##### Unigrams only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ62bUxZ0sux",
        "outputId": "53aaef7d-b7f7-418f-90fc-171d110b5fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.453025229957307,\n",
            " Test classification accuracy = 0.414453212516492\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4597341332569921,\n",
            " Test classification accuracy = 0.41831171740808043\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4630512440721425,\n",
            " Test classification accuracy = 0.4201289487441189\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.46482493372001843,\n",
            " Test classification accuracy = 0.4208259689825994\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.467880658692324,\n",
            " Test classification accuracy = 0.42197107366010306\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.472081502595188,\n",
            " Test classification accuracy = 0.4242363894351647\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.47398588516448636,\n",
            " Test classification accuracy = 0.4246346867142964\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4790766856275127,\n",
            " Test classification accuracy = 0.4255806427522342\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4820701758753314,\n",
            " Test classification accuracy = 0.42617808867093177\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.48238757297021445,\n",
            " Test classification accuracy = 0.42617808867093177\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_split, 1, 'description', MultinomialNB, CountVectorizer, topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1qgzTlHvJ_qS",
        "outputId": "cb7b75f1-86ec-4b04-fa90-565ff566cb6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>By</th>\n",
              "      <th>Preprocessed</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Ngram</th>\n",
              "      <th>TopKFeatures</th>\n",
              "      <th>TrainAccuracy</th>\n",
              "      <th>TestAccuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>5000</td>\n",
              "      <td>0.453025</td>\n",
              "      <td>0.414453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.459734</td>\n",
              "      <td>0.418312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>7000</td>\n",
              "      <td>0.463051</td>\n",
              "      <td>0.420129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>8000</td>\n",
              "      <td>0.464825</td>\n",
              "      <td>0.420826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>9000</td>\n",
              "      <td>0.467881</td>\n",
              "      <td>0.421971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Classifier           By  ... TrainAccuracy TestAccuracy\n",
              "0  MultinomialNB  description  ...      0.453025     0.414453\n",
              "1  MultinomialNB  description  ...      0.459734     0.418312\n",
              "2  MultinomialNB  description  ...      0.463051     0.420129\n",
              "3  MultinomialNB  description  ...      0.464825     0.420826\n",
              "4  MultinomialNB  description  ...      0.467881     0.421971\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn9sik38AZOh"
      },
      "source": [
        "##### Unigrams and Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RMit8iZH8cE",
        "outputId": "7df69f63-5441-4db8-cc1c-e14c61c35c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.43917178028652865,\n",
            " Test classification accuracy = 0.4083044982698962\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4464470195790443,\n",
            " Test classification accuracy = 0.41191406736202735\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4479966642187675,\n",
            " Test classification accuracy = 0.41315874635931393\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.44713782502084864,\n",
            " Test classification accuracy = 0.4132832142590426\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4463910083270061,\n",
            " Test classification accuracy = 0.41318363993925966\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4454325935699083,\n",
            " Test classification accuracy = 0.41271066192029077\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4441381113005813,\n",
            " Test classification accuracy = 0.4119389609419731\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.44271293610983187,\n",
            " Test classification accuracy = 0.41131662144332976\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4413313252262232,\n",
            " Test classification accuracy = 0.4104204525652834\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4415864875966194,\n",
            " Test classification accuracy = 0.41074406910457795\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_split, 1, 'description', MultinomialNB, CountVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHuGk_-6O1fD"
      },
      "source": [
        "#### Using TFIDF vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7SvBCLRA7Q"
      },
      "source": [
        "##### Unigrams only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L6zBxHiRCqo",
        "outputId": "b2943caf-fd0b-4e5b-8ae0-41514dc1499b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35364882189666547,\n",
            " Test classification accuracy = 0.34455204002887657\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3588454213913195,\n",
            " Test classification accuracy = 0.349157352318837\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3564307140812288,\n",
            " Test classification accuracy = 0.34719075950312417\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35699082660161063,\n",
            " Test classification accuracy = 0.34763884394214734\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3556465565526941,\n",
            " Test classification accuracy = 0.3460456548256205\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.36009633935350566,\n",
            " Test classification accuracy = 0.3482611834407906\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3604012895034914,\n",
            " Test classification accuracy = 0.34791267332155035\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3621874260962647,\n",
            " Test classification accuracy = 0.3490826715789998\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.36274753861664655,\n",
            " Test classification accuracy = 0.3485599064001394\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.36160864315853675,\n",
            " Test classification accuracy = 0.34853501282019367\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_split, 1, 'description', MultinomialNB, TfidfVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuBZ9NyLRC5V"
      },
      "source": [
        "##### Unigrams and Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgMXbCnMRFBS",
        "outputId": "6c082907-5d5d-440b-a890-c9e76741a689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2694639100832701,\n",
            " Test classification accuracy = 0.2991461502078614\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.27358384884430115,\n",
            " Test classification accuracy = 0.3030544422593413\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.270241844139356,\n",
            " Test classification accuracy = 0.2990714694680242\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.26737282334051105,\n",
            " Test classification accuracy = 0.29538721963605585\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.264945669085523,\n",
            " Test classification accuracy = 0.29210126708321926\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.26276745372848237,\n",
            " Test classification accuracy = 0.28946254760897167\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2607572721275563,\n",
            " Test classification accuracy = 0.2870976575141271\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2589960294245777,\n",
            " Test classification accuracy = 0.28495680963879416\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.25754596034403354,\n",
            " Test classification accuracy = 0.2830400039829728\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.25755218381648226,\n",
            " Test classification accuracy = 0.2829404296631899\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_split, 1, 'description', MultinomialNB, TfidfVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGHKqsjsKUbS"
      },
      "source": [
        "### Result df after running training on processed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "xcRCqHgdKcBJ",
        "outputId": "324afb00-0295-4e64-e4cc-1a84332ecb85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>By</th>\n",
              "      <th>Preprocessed</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Ngram</th>\n",
              "      <th>TopKFeatures</th>\n",
              "      <th>TrainAccuracy</th>\n",
              "      <th>TestAccuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>14000</td>\n",
              "      <td>0.482388</td>\n",
              "      <td>0.426178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>13000</td>\n",
              "      <td>0.482070</td>\n",
              "      <td>0.426178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>12000</td>\n",
              "      <td>0.479077</td>\n",
              "      <td>0.425581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.473986</td>\n",
              "      <td>0.424635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>description</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.472082</td>\n",
              "      <td>0.424236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Classifier           By  ... TrainAccuracy TestAccuracy\n",
              "9  MultinomialNB  description  ...      0.482388     0.426178\n",
              "8  MultinomialNB  description  ...      0.482070     0.426178\n",
              "7  MultinomialNB  description  ...      0.479077     0.425581\n",
              "6  MultinomialNB  description  ...      0.473986     0.424635\n",
              "5  MultinomialNB  description  ...      0.472082     0.424236\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(results_df))\n",
        "results_df.sort_values(by=['TrainAccuracy', 'TestAccuracy'], ascending=[False, False]).head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-u3SpjZCCIO"
      },
      "source": [
        "### Training on raw data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQv8y6oJO5er"
      },
      "source": [
        "#### Using CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E1e10_9CEuP"
      },
      "source": [
        "##### Unigrams only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv7doN-dCDy6",
        "outputId": "291ccdc5-3329-4524-c637-5d86707822d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.44793442949428064,\n",
            " Test classification accuracy = 0.41198874810186453\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.454935835999054,\n",
            " Test classification accuracy = 0.4157476786736701\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.45702069926936434,\n",
            " Test classification accuracy = 0.4168429961912823\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.46163851582629045,\n",
            " Test classification accuracy = 0.41816235592840606\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4634433228364098,\n",
            " Test classification accuracy = 0.4191829927061811\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4665426121158562,\n",
            " Test classification accuracy = 0.4211495855218939\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4698472759861092,\n",
            " Test classification accuracy = 0.42264320031863784\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4731394929114649,\n",
            " Test classification accuracy = 0.4224938388389634\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.47379918099102575,\n",
            " Test classification accuracy = 0.4227676682183665\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4742099301726391,\n",
            " Test classification accuracy = 0.42244405167907195\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# raw_dataset_sh_ - raw dataset train-test split\n",
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_dataset_sh_, 0, 'description', MultinomialNB, CountVectorizer, topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk-hf3-HCMn-"
      },
      "source": [
        "##### Unigrams and Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdkeD7vHCOUC",
        "outputId": "bbd70a0a-cc11-44eb-c98b-d829c1054de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.42051380988536363,\n",
            " Test classification accuracy = 0.39227303278484477\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.42929512951046167,\n",
            " Test classification accuracy = 0.397177068034154\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.43520120486426606,\n",
            " Test classification accuracy = 0.40158323168454857\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4411197271629678,\n",
            " Test classification accuracy = 0.4053172686764083\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.44459242478933547,\n",
            " Test classification accuracy = 0.4071593935923925\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4442688042220037,\n",
            " Test classification accuracy = 0.4080555624704389\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.44359044572509676,\n",
            " Test classification accuracy = 0.4082547111100047\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4426880422200371,\n",
            " Test classification accuracy = 0.40890194418859377\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.44151180592723516,\n",
            " Test classification accuracy = 0.4083293918498419\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4407027545089058,\n",
            " Test classification accuracy = 0.40847875332951633\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_dataset_sh_, 0, 'description', MultinomialNB, CountVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_3oDGytCOoH"
      },
      "source": [
        "##### Bigrams only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtUgzzDuFWoD",
        "outputId": "96a0711d-a5ce-43d9-f34d-509354d1fbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3305846330018297,\n",
            " Test classification accuracy = 0.30614124617261207\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3301240960406268,\n",
            " Test classification accuracy = 0.30522018371462\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3288296137712998,\n",
            " Test classification accuracy = 0.3044484827363023\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.32752890802952417,\n",
            " Test classification accuracy = 0.3041497597769535\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.32637134215406827,\n",
            " Test classification accuracy = 0.3032784844788529\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.325282234475548,\n",
            " Test classification accuracy = 0.30238231560080653\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.32711193537546207,\n",
            " Test classification accuracy = 0.3029797615195041\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.32647091771324727,\n",
            " Test classification accuracy = 0.30240720918075226\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.32589213477551937,\n",
            " Test classification accuracy = 0.30173508252221753\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.32538803350717566,\n",
            " Test classification accuracy = 0.3009882751238456\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_dataset_sh_, 0, 'description', MultinomialNB, CountVectorizer, ngram=(2, 2), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TJTmY_hPBHM"
      },
      "source": [
        "#### Using TFIDF vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQclZfCWSRON"
      },
      "source": [
        "##### Unigrams only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMmV0yO_PEQo",
        "outputId": "ee7dcbbf-904d-4418-b200-02ade41a0bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3539662189915485,\n",
            " Test classification accuracy = 0.34577182544621743\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35713396646793044,\n",
            " Test classification accuracy = 0.3477882054218217\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35519224306394,\n",
            " Test classification accuracy = 0.3451494859475741\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35451388456703303,\n",
            " Test classification accuracy = 0.34422842348958205\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35499931541803065,\n",
            " Test classification accuracy = 0.3438052326305046\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3550739970874149,\n",
            " Test classification accuracy = 0.3421124691941948\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.355690120859835,\n",
            " Test classification accuracy = 0.3422618306738692\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3571152960505844,\n",
            " Test classification accuracy = 0.34238629857359787\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.355490969741477,\n",
            " Test classification accuracy = 0.3410918324164198\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_dataset_sh_, 0, 'description', MultinomialNB, TfidfVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiTwI_EOSnx9"
      },
      "source": [
        "##### Unigrams and Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WerU051iSp9p",
        "outputId": "92614657-4726-4ff6-c5d8-f394da14d42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2768511718798621,\n",
            " Test classification accuracy = 0.28667446665504964\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2814254241296474,\n",
            " Test classification accuracy = 0.29020935500734363\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.28402683561319875,\n",
            " Test classification accuracy = 0.2930970102810485\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.28744352198752815,\n",
            " Test classification accuracy = 0.29531253889621867\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2841637520070699,\n",
            " Test classification accuracy = 0.2922257349829479\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2810582392551748,\n",
            " Test classification accuracy = 0.2887904209504369\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2784817216614182,\n",
            " Test classification accuracy = 0.28630106295586366\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2763035063043776,\n",
            " Test classification accuracy = 0.28393617286101913\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.2742124195616186,\n",
            " Test classification accuracy = 0.2813721341266088\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.27405683275040144,\n",
            " Test classification accuracy = 0.280973836847477\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_dataset_sh_, 0, 'description', MultinomialNB, TfidfVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewWpjvLIS32a"
      },
      "source": [
        "##### Bigrams only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eAzJYQ7S5Wg"
      },
      "outputs": [],
      "source": [
        "for i in (TOP_KS):\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_dataset_sh_, 0, 'description', MultinomialNB, TfidfVectorizer, ngram=(2, 2), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAjx6C1VZGYw"
      },
      "source": [
        "### *Results_df* after recording accuracies on raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNMjTlROZP31"
      },
      "outputs": [],
      "source": [
        "results_df.sort_values(by=['TrainAccuracy', 'TestAccuracy'], ascending=[False, False]).head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1pLTt8g4aHf"
      },
      "source": [
        "## Using imblearn.RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HMpyzHy4hp_",
        "outputId": "72b1d02e-4981-4d12-ef45-6c3596c49547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ARTS', 32739), ('ARTS & CULTURE', 32739), ('BLACK VOICES', 32739), ('BUSINESS', 32739), ('COLLEGE', 32739), ('COMEDY', 32739), ('CRIME', 32739), ('CULTURE & ARTS', 32739), ('DIVORCE', 32739), ('EDUCATION', 32739), ('ENTERTAINMENT', 32739), ('ENVIRONMENT', 32739), ('FIFTY', 32739), ('FOOD & DRINK', 32739), ('GOOD NEWS', 32739), ('GREEN', 32739), ('HEALTHY LIVING', 32739), ('HOME & LIVING', 32739), ('IMPACT', 32739), ('LATINO VOICES', 32739), ('MEDIA', 32739), ('MONEY', 32739), ('PARENTING', 32739), ('PARENTS', 32739), ('POLITICS', 32739), ('QUEER VOICES', 32739), ('RELIGION', 32739), ('SCIENCE', 32739), ('SPORTS', 32739), ('STYLE', 32739), ('STYLE & BEAUTY', 32739), ('TASTE', 32739), ('TECH', 32739), ('THE WORLDPOST', 32739), ('TRAVEL', 32739), ('WEDDINGS', 32739), ('WEIRD NEWS', 32739), ('WELLNESS', 32739), ('WOMEN', 32739), ('WORLD NEWS', 32739), ('WORLDPOST', 32739)]\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "\n",
        "cv_u = CountVectorizer()\n",
        "X = cv_u.fit_transform(df_1.processed_description)\n",
        "y = df_1.category\n",
        "\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "from collections import Counter\n",
        "print(sorted(Counter(y_resampled).items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaZ53EMI5N1a",
        "outputId": "1b2bdeea-de48-4835-f628-3d38a7d0c1a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6288124860314386"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_resampled, y_resampled, test_size=0.2)\n",
        "\n",
        "classifier_u = MultinomialNB()\n",
        "classifier_u.fit(X_train_over, y_train_over)\n",
        "y_pred_over = classifier_u.predict(X_test_over)\n",
        "\n",
        "accuracy_score(y_test_over, y_pred_over)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2FVzSzsGR96"
      },
      "source": [
        "Checking our over-sampled classifier on the non-over-sampled test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y07b42brGXYb"
      },
      "outputs": [],
      "source": [
        "# y_pred_by_over = classifier_u.predict(X_test)\n",
        "# accuracy_score(y_test, y_pred_by_over)\n",
        "\n",
        "# Causes ValueError: X has 1192532 features, but MultinomialNB is expecting 88702 features as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKve0TsVFGh4"
      },
      "source": [
        "## Using imlearn.under_sampling.ClusterCentroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65Dex63gFtx1"
      },
      "outputs": [],
      "source": [
        "# from imblearn.under_sampling import ClusterCentroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_hZuWBzFji4"
      },
      "outputs": [],
      "source": [
        "# cc = ClusterCentroids(random_state=0)\n",
        "# X_under, y_under = cc.fit_resample(X, y)\n",
        "# print(sorted(Counter(y_under).items()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruQZmrZ7nYaj"
      },
      "source": [
        "**IMPORTANT**\n",
        "\n",
        "The above cell takes too long to execute, so I did not get any results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0gjKiGdnj5q"
      },
      "source": [
        "## Manual undersampling using pandas sample [although seems inefficient]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3ffrl_Cn8ic",
        "outputId": "370ad036-4362-4b31-bc9c-77df4e26fea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('EDUCATION', 1004)\n"
          ]
        }
      ],
      "source": [
        "els = list(Counter(y).items())\n",
        "min_tuple = min(els, key=lambda x: x[1])\n",
        "print(min_tuple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "7pErWlDbpGSR",
        "outputId": "fb1ab51c-a288-4b9c-e91a-e1aabb4c2218"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "      <th>processed_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66018</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>could easily googled didn’t</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64882</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>part plea deal samuel mchenry admitted sexual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103858</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>“i grossly underestimated resources would nece...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11932</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>want cops come fk that’s want heard saying aud...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       category  ...                              processed_description\n",
              "66018     CRIME  ...                        could easily googled didn’t\n",
              "64882     CRIME  ...  part plea deal samuel mchenry admitted sexual ...\n",
              "103858    CRIME  ...                                                   \n",
              "4411      CRIME  ...  “i grossly underestimated resources would nece...\n",
              "11932     CRIME  ...  want cops come fk that’s want heard saying aud...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "empty_df = pd.DataFrame(columns=df.columns)\n",
        "for i in range(len(els)):\n",
        "    curr_df = df_1[df_1['category'] == els[i][0]]\n",
        "    sampled_df = curr_df.sample(min_tuple[1])\n",
        "    empty_df = empty_df.append(sampled_df)\n",
        "\n",
        "\n",
        "empty_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3MRW90RrlXC",
        "outputId": "1ca003e0-5a49-4fa6-c1bd-a5119ef23d44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([('CRIME', 1004), ('ENTERTAINMENT', 1004), ('WORLD NEWS', 1004), ('IMPACT', 1004), ('POLITICS', 1004), ('WEIRD NEWS', 1004), ('BLACK VOICES', 1004), ('WOMEN', 1004), ('COMEDY', 1004), ('QUEER VOICES', 1004), ('SPORTS', 1004), ('BUSINESS', 1004), ('TRAVEL', 1004), ('MEDIA', 1004), ('TECH', 1004), ('RELIGION', 1004), ('SCIENCE', 1004), ('LATINO VOICES', 1004), ('EDUCATION', 1004), ('COLLEGE', 1004), ('PARENTS', 1004), ('ARTS & CULTURE', 1004), ('STYLE', 1004), ('GREEN', 1004), ('TASTE', 1004), ('HEALTHY LIVING', 1004), ('THE WORLDPOST', 1004), ('GOOD NEWS', 1004), ('WORLDPOST', 1004), ('FIFTY', 1004), ('ARTS', 1004), ('WELLNESS', 1004), ('PARENTING', 1004), ('HOME & LIVING', 1004), ('STYLE & BEAUTY', 1004), ('DIVORCE', 1004), ('WEDDINGS', 1004), ('FOOD & DRINK', 1004), ('MONEY', 1004), ('ENVIRONMENT', 1004), ('CULTURE & ARTS', 1004)])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(empty_df.category.values).items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXMNYpF7rwbe",
        "outputId": "8f663bab-dd16-4670-ed6b-3996904ded16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.25482813069355037"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_u = CountVectorizer()\n",
        "X_u = cv_u.fit_transform(empty_df.processed_description)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_u, empty_df['category'].values, test_size=0.2)\n",
        "\n",
        "classifier_u = MultinomialNB()\n",
        "classifier_u.fit(X_train, y_train)\n",
        "y_pred = classifier_u.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHXmYceAoMTL"
      },
      "source": [
        "# Model, making classifications based on headline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(df.headline, df['category'], \n",
        "                                                    test_size=0.2, stratify=df.category,\n",
        "                                                    random_state=1)\n",
        "\n",
        "df['processed_headline'] = df['headline'].apply(lambda x: ' '.join(cleaning_function(x)))\n",
        "processed_headline_split = train_test_split(df.processed_headline, df['category'], \n",
        "                                                    test_size=0.2, stratify=df.category,\n",
        "                                                    random_state=1)\n",
        "raw_headline_split = (X_train_h, X_test_h, y_train_h, y_test_h)"
      ],
      "metadata": {
        "id": "yJv-FNFyni6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.sort_values(by=['TrainAccuracy', 'TestAccuracy'], ascending=[False, False]).iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKUJWDGdpPqw",
        "outputId": "0fd63d99-b01b-49e1-bd69-5532fd35444b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier         MultinomialNB\n",
              "By                   description\n",
              "Preprocessed                   1\n",
              "Vectorizer       CountVectorizer\n",
              "Ngram                     (1, 1)\n",
              "TopKFeatures               14000\n",
              "TrainAccuracy           0.482388\n",
              "TestAccuracy            0.426178\n",
              "Name: 9, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8__rIzH5lUY"
      },
      "source": [
        "### Without preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams only"
      ],
      "metadata": {
        "id": "d81oPZNFqU9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8vkf7_q5kfM",
        "outputId": "98c1e93d-18c3-4571-ee07-2598d54b5ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.580569074320708,\n",
            " Test classification accuracy = 0.537626646087974\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5885786833621688,\n",
            " Test classification accuracy = 0.5408379179009734\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5952191284649183,\n",
            " Test classification accuracy = 0.544024296134027\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5996191234861403,\n",
            " Test classification accuracy = 0.5452440815513679\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6030669272227132,\n",
            " Test classification accuracy = 0.546911951407732\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6064649431796966,\n",
            " Test classification accuracy = 0.5476338652261582\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6097135957979114,\n",
            " Test classification accuracy = 0.5487042891638246\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6143314123548375,\n",
            " Test classification accuracy = 0.5491025864429564\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6148541840405273,\n",
            " Test classification accuracy = 0.5481815239849642\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6139953448426084,\n",
            " Test classification accuracy = 0.5473849294267008\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_headline_split, 0, 'headline', MultinomialNB, CountVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams and Bigrams"
      ],
      "metadata": {
        "id": "y14FHumuqp2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_headline_split, 0, 'headline', MultinomialNB, CountVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNqGE1jYqpUd",
        "outputId": "7dc3afb8-bea8-488c-fa33-88e8a0c1597c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5515365753475809,\n",
            " Test classification accuracy = 0.518856886808892\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5596021956410799,\n",
            " Test classification accuracy = 0.5237609220582012\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5666782838152375,\n",
            " Test classification accuracy = 0.5277936820094098\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5740593221393809,\n",
            " Test classification accuracy = 0.5310298474023549\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5795422013666746,\n",
            " Test classification accuracy = 0.5342162256354086\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5833883073399634,\n",
            " Test classification accuracy = 0.5370292001692764\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5825854793940827,\n",
            " Test classification accuracy = 0.5362077120310672\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5819320147869705,\n",
            " Test classification accuracy = 0.5352617559931294\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5827223957879538,\n",
            " Test classification accuracy = 0.5349630330337806\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5816332881094335,\n",
            " Test classification accuracy = 0.5344402678549203\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIl8d_da6SZk"
      },
      "source": [
        "### With preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams"
      ],
      "metadata": {
        "id": "YtV-TC0dqx_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXCnI4O8Shao",
        "outputId": "73f7c463-9b57-4c37-a99a-fa81fac129c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5719993527588654,\n",
            " Test classification accuracy = 0.5297851684050683\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5801521016666459,\n",
            " Test classification accuracy = 0.5343157999551915\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5903523730100447,\n",
            " Test classification accuracy = 0.5393940902641209\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5930533600527751,\n",
            " Test classification accuracy = 0.5411615344402678\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5982063952402883,\n",
            " Test classification accuracy = 0.543003659356252\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6030731506951619,\n",
            " Test classification accuracy = 0.5459411017898484\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6064711666521452,\n",
            " Test classification accuracy = 0.5469866321475692\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6118295764304651,\n",
            " Test classification accuracy = 0.5491025864429564\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6149350891823602,\n",
            " Test classification accuracy = 0.5494013094023051\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6164224990975965,\n",
            " Test classification accuracy = 0.548579821264096\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_headline_split, 0, 'headline', MultinomialNB, CountVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams and Bigrams"
      ],
      "metadata": {
        "id": "XTzDT6-nq5rj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xADQ4pXK53zQ",
        "outputId": "af591227-a72d-4cdb-eaef-1155b25dafc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5476282346498053,\n",
            " Test classification accuracy = 0.5163177416544273\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5583699480962397,\n",
            " Test classification accuracy = 0.5227402852804262\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.566709401177481,\n",
            " Test classification accuracy = 0.5280426178088671\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5753102401015671,\n",
            " Test classification accuracy = 0.5334196310771452\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5745758703526219,\n",
            " Test classification accuracy = 0.5330462273779593\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5737543719893952,\n",
            " Test classification accuracy = 0.533071120957905\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5744389539587508,\n",
            " Test classification accuracy = 0.5339672898359513\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5735489973985886,\n",
            " Test classification accuracy = 0.5327475044186104\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5724349958302735,\n",
            " Test classification accuracy = 0.5307311244430062\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5711156196711518,\n",
            " Test classification accuracy = 0.529262403226208\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_headline_split, 0, 'headline', MultinomialNB, CountVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVE6gGt17FIT"
      },
      "source": [
        "### Using oversampling for classification based on headline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKn7l5Jl8xOg"
      },
      "source": [
        "#### For non-preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2ADp4s36uSC"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler(random_state=0)\n",
        "\n",
        "cv_u = CountVectorizer()\n",
        "X = cv_u.fit_transform(df.headline)\n",
        "y = df.category\n",
        "\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjWQxnoB8YgI",
        "outputId": "25a74c4b-e9ab-4390-d1a3-6b5a54cba84a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7501005736422558"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2)\n",
        "\n",
        "classifier_u = MultinomialNB()\n",
        "classifier_u.fit(X_train, y_train)\n",
        "y_pred = classifier_u.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYmplzaN80Wh"
      },
      "source": [
        "#### For preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10fIV_z58mE_"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler(random_state=0)\n",
        "\n",
        "cv_u = CountVectorizer()\n",
        "X = cv_u.fit_transform(new_df.processed_headline)\n",
        "y = new_df.category\n",
        "\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIlHadyi9FsR",
        "outputId": "22f2547b-6c7c-4dcc-cd96-6177614e4198"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7662929300454444"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2)\n",
        "\n",
        "classifier_u = MultinomialNB()\n",
        "classifier_u.fit(X_train, y_train)\n",
        "y_pred = classifier_u.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTzZov8e_SP_"
      },
      "source": [
        "It might be because some news samples, present in the test set, are also present in the test set, which drives up the accuracy score./?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model, making classifications based on full_text: headdline + short_description"
      ],
      "metadata": {
        "id": "9duuR6w8wu1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['full_text'] = df['short_description'] + df['headline']"
      ],
      "metadata": {
        "id": "_j0LEwtMw3B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(df.full_text, df['category'], \n",
        "                                                    test_size=0.2, stratify=df.category,\n",
        "                                                    random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "df['processed_fulltext'] = df['full_text'].apply(lambda x: ' '.join(cleaning_function(x)))\n",
        "processed_fulltext_split = train_test_split(df.processed_fulltext, df['category'], \n",
        "                                                    test_size=0.2, stratify=df.category,\n",
        "                                                    random_state=1)\n",
        "raw_fulltext_split = (X_train_f, X_test_f, y_train_f, y_test_f)"
      ],
      "metadata": {
        "id": "XOa_EL-Exg8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without preprocessing"
      ],
      "metadata": {
        "id": "xbFv6e_4yGER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CountVectorizer"
      ],
      "metadata": {
        "id": "q4Ze0lCDyh-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams"
      ],
      "metadata": {
        "id": "CgkGM0dKykJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_fulltext_split, 0, 'full_text', MultinomialNB, CountVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXTBQPieyImf",
        "outputId": "357c6ff3-eb0e-4c29-ff91-9a8ce8fba17e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6058363724623791,\n",
            " Test classification accuracy = 0.5591098055811407\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6161860071445464,\n",
            " Test classification accuracy = 0.5645366060093102\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6182024122179212,\n",
            " Test classification accuracy = 0.5662791566055114\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6209531870402409,\n",
            " Test classification accuracy = 0.569565109158348\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6240649232645847,\n",
            " Test classification accuracy = 0.5709840432152548\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6297967413898259,\n",
            " Test classification accuracy = 0.5739463792287969\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6302821722408235,\n",
            " Test classification accuracy = 0.5736227626895024\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6307862735091672,\n",
            " Test classification accuracy = 0.5730751039306963\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6321927782825706,\n",
            " Test classification accuracy = 0.572826168131239\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.633319226795783,\n",
            " Test classification accuracy = 0.5722287222125414\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams and Bigrams"
      ],
      "metadata": {
        "id": "9ggyjO77ymmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_fulltext_split, 0, 'full_text', MultinomialNB, CountVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26HEKMB8ypNR",
        "outputId": "4aeff23d-5deb-4cb2-a9e1-f60b4730019a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5714330167660348,\n",
            " Test classification accuracy = 0.5390455801448807\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5802827945880683,\n",
            " Test classification accuracy = 0.5445470613128874\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5883484148815673,\n",
            " Test classification accuracy = 0.5493017350825222\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5965260576791427,\n",
            " Test classification accuracy = 0.5529113041746534\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6007953597789423,\n",
            " Test classification accuracy = 0.5554006621692266\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6054069528634197,\n",
            " Test classification accuracy = 0.5582634238629858\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6090974720254914,\n",
            " Test classification accuracy = 0.5604291653182644\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6133418802354962,\n",
            " Test classification accuracy = 0.5618480993751711\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.616254465341482,\n",
            " Test classification accuracy = 0.5637649050309925\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6196711517158113,\n",
            " Test classification accuracy = 0.5653332005675736\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bigrams"
      ],
      "metadata": {
        "id": "AgkQiCWDypZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_fulltext_split, 0, 'full_text', MultinomialNB, CountVectorizer, ngram=(2, 2), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JhcNcsMyrHd",
        "outputId": "c55a33dc-8819-42e5-8a92-0316a668a45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.43783373371006085,\n",
            " Test classification accuracy = 0.4101964103457718\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.45049850014313986,\n",
            " Test classification accuracy = 0.41955639640536707\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4631072553241807,\n",
            " Test classification accuracy = 0.42834383012621047\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.471284898121756,\n",
            " Test classification accuracy = 0.43347190759503124\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4803711678968397,\n",
            " Test classification accuracy = 0.43932189888227824\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.487833111362816,\n",
            " Test classification accuracy = 0.4442010405516417\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4869804956373458,\n",
            " Test classification accuracy = 0.44367827537278137\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.48562377864353196,\n",
            " Test classification accuracy = 0.4428070000746807\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.484148815673193,\n",
            " Test classification accuracy = 0.4419357247765801\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.48264273534061064,\n",
            " Test classification accuracy = 0.44158721465733985\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TfidfVectorizer"
      ],
      "metadata": {
        "id": "PcMKfXDBysPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams"
      ],
      "metadata": {
        "id": "nr6tzly7yvK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_fulltext_split, 0, 'full_text', MultinomialNB, TfidfVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP0P0uf3yx97",
        "outputId": "13f1fa42-59fa-4372-f0ae-c705d3f86fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.48479605680785653,\n",
            " Test classification accuracy = 0.47449652734559755\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4881256145679043,\n",
            " Test classification accuracy = 0.47648801374125616\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4809686212519137,\n",
            " Test classification accuracy = 0.4685220681586219\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.47678022429394706,\n",
            " Test classification accuracy = 0.46521122202583953\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4733510909747203,\n",
            " Test classification accuracy = 0.4617510144133828\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.47484472436240527,\n",
            " Test classification accuracy = 0.4620746309526773\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.46927471652082997,\n",
            " Test classification accuracy = 0.45652336262477905\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.46536637582305423,\n",
            " Test classification accuracy = 0.45254038983346195\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4633561942221282,\n",
            " Test classification accuracy = 0.44982698961937717\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4607485592661281,\n",
            " Test classification accuracy = 0.44631699484702897\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams and Bigrams"
      ],
      "metadata": {
        "id": "QmzOS1hAyyUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(raw_fulltext_split, 0, 'full_text', MultinomialNB, TfidfVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "6WjRJYr-y0YE",
        "outputId": "03616ed4-d158-4728-a985-7c664444d945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.36424117200433154,\n",
            " Test classification accuracy = 0.38368474770356725\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3678819033868137,\n",
            " Test classification accuracy = 0.3870702745761868\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3721823228488568,\n",
            " Test classification accuracy = 0.39003261058972893\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-07182c879635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTOP_KS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"For top {i} features selected:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwrite_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_fulltext_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-eafc18e706d2>\u001b[0m in \u001b[0;36mwrite_df\u001b[0;34m(dataset, preprocessed, by, clf, vect, ngram, topk, display)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mx_train_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Vectorize validation texts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With preprocessing"
      ],
      "metadata": {
        "id": "dtRt2piAyIxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CountVectorizer"
      ],
      "metadata": {
        "id": "aCHS__vyy25_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams"
      ],
      "metadata": {
        "id": "L5wVzCIjy47v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_fulltext_split, 1, 'full_text', MultinomialNB, CountVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_ELx2jJyNao",
        "outputId": "fe0e8f1b-ce50-4e78-93d1-14d8d2fd9933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5973102152076772,\n",
            " Test classification accuracy = 0.5491025864429564\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6066329769358111,\n",
            " Test classification accuracy = 0.5541808767518857\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.608985449521415,\n",
            " Test classification accuracy = 0.5552015135296607\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6085498064500069,\n",
            " Test classification accuracy = 0.5562719374673272\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6145430104180929,\n",
            " Test classification accuracy = 0.5596823579198925\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6152400393323458,\n",
            " Test classification accuracy = 0.5605038460581017\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6162606888139306,\n",
            " Test classification accuracy = 0.5613253341963108\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6216377690095966,\n",
            " Test classification accuracy = 0.5623459709740858\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6207851532841264,\n",
            " Test classification accuracy = 0.5623210773941401\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6203557336851669,\n",
            " Test classification accuracy = 0.5623708645540315\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams and Bigrams"
      ],
      "metadata": {
        "id": "UYxYXDDVy7KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_fulltext_split, 1, 'full_text', MultinomialNB, CountVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuCSAVDny9xY",
        "outputId": "ecb08a9c-42e4-44ef-e1ab-5aa45863019e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.573499209618999,\n",
            " Test classification accuracy = 0.5373777102885166\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.583058463300183,\n",
            " Test classification accuracy = 0.5456174852505539\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5888649630948084,\n",
            " Test classification accuracy = 0.5490279057031192\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.5959659451587608,\n",
            " Test classification accuracy = 0.5514923701177467\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6017786684258348,\n",
            " Test classification accuracy = 0.5540813024321027\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6058737132970712,\n",
            " Test classification accuracy = 0.5557740658684125\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6105662115233816,\n",
            " Test classification accuracy = 0.5599312937193498\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6115432966978255,\n",
            " Test classification accuracy = 0.5598566129795126\n",
            "\n",
            "\n",
            "For top 13000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6105102002713434,\n",
            " Test classification accuracy = 0.5594085285404894\n",
            "\n",
            "\n",
            "For top 14000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.6096077967662837,\n",
            " Test classification accuracy = 0.5589604441014663\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TfidfVectorizer"
      ],
      "metadata": {
        "id": "Uhvn8C1_y994"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams"
      ],
      "metadata": {
        "id": "gOaA8Yn2zAnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_fulltext_split, 1, 'full_text', MultinomialNB, TfidfVectorizer, ngram=(1, 1), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QkBe2eLfy_lZ",
        "outputId": "548c5472-81e9-4e7b-8643-1ddec4aa0a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4663621314148442,\n",
            " Test classification accuracy = 0.46065569689577057\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4693618451351116,\n",
            " Test classification accuracy = 0.46232356675213465\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4630948083792833,\n",
            " Test classification accuracy = 0.4570710213835852\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.4563423407724574,\n",
            " Test classification accuracy = 0.4507231584974235\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.456728196064276,\n",
            " Test classification accuracy = 0.4503497547982375\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.45183654671960766,\n",
            " Test classification accuracy = 0.44624231410719173\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-93d0f07308b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTOP_KS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"For top {i} features selected:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwrite_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_fulltext_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-eafc18e706d2>\u001b[0m in \u001b[0;36mwrite_df\u001b[0;34m(dataset, preprocessed, by, clf, vect, ngram, topk, display)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Vectorize validation texts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Select top 'k' of the vectorized features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_classif\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"The TF-IDF vectorizer is not fitted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unigrams and Bigrams"
      ],
      "metadata": {
        "id": "XwoSMbvSzDBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in TOP_KS:\n",
        "    print(f\"For top {i} features selected:\\n\")\n",
        "    write_df(processed_fulltext_split, 1, 'full_text', MultinomialNB, TfidfVectorizer, ngram=(1, 2), topk=i)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6GER6qz0zEzB",
        "outputId": "3c163fc0-1aa0-43f2-9c38-c598730ea7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For top 5000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.33899876775245513,\n",
            " Test classification accuracy = 0.3865724029772722\n",
            "\n",
            "\n",
            "For top 6000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.34685278998269875,\n",
            " Test classification accuracy = 0.39209877772522467\n",
            "\n",
            "\n",
            "For top 7000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.34844599892956274,\n",
            " Test classification accuracy = 0.3928206915436509\n",
            "\n",
            "\n",
            "For top 8000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.3519933782253146,\n",
            " Test classification accuracy = 0.39441388066017774\n",
            "\n",
            "\n",
            "For top 9000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35569634433228364,\n",
            " Test classification accuracy = 0.396803664334968\n",
            "\n",
            "\n",
            "For top 10000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.35768785551586363,\n",
            " Test classification accuracy = 0.3975006845734485\n",
            "\n",
            "\n",
            "For top 11000 features selected:\n",
            "\n",
            "Train classification accuracy = 0.36062533451164414,\n",
            " Test classification accuracy = 0.39832217271165765\n",
            "\n",
            "\n",
            "For top 12000 features selected:\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-4299caead42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTOP_KS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"For top {i} features selected:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwrite_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_fulltext_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'full_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-eafc18e706d2>\u001b[0m in \u001b[0;36mwrite_df\u001b[0;34m(dataset, preprocessed, by, clf, vect, ngram, topk, display)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         )\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_base.py\u001b[0m in \u001b[0;36mget_support\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mindices\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36m_get_support_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;31m# Request a stable sort. Mergesort takes more memory (~40MB per\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m# megafeature on x86-64).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mergesort\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \"\"\"\n\u001b[0;32m-> 1107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking final results and saving it to .csv table for later use"
      ],
      "metadata": {
        "id": "0lqn8YaXKEet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(results_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKxtpjvP6nMI",
        "outputId": "f6d3228e-30c7-4fe7-b9b0-dd91af7e5ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing top 5 rows by test accuracy"
      ],
      "metadata": {
        "id": "aAJrzlny7ARx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.sort_values(by='TestAccuracy', ascending=False).head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s7gqKPl86-IO",
        "outputId": "e58a787b-a437-4ea6-e69a-cb1f98767ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>By</th>\n",
              "      <th>Preprocessed</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Ngram</th>\n",
              "      <th>TopKFeatures</th>\n",
              "      <th>TrainAccuracy</th>\n",
              "      <th>TestAccuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.629797</td>\n",
              "      <td>0.573946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.630282</td>\n",
              "      <td>0.573623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>12000</td>\n",
              "      <td>0.630786</td>\n",
              "      <td>0.573075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>13000</td>\n",
              "      <td>0.632193</td>\n",
              "      <td>0.572826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>14000</td>\n",
              "      <td>0.633319</td>\n",
              "      <td>0.572229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Classifier         By  ... TrainAccuracy TestAccuracy\n",
              "146  MultinomialNB  full_text  ...      0.629797     0.573946\n",
              "147  MultinomialNB  full_text  ...      0.630282     0.573623\n",
              "148  MultinomialNB  full_text  ...      0.630786     0.573075\n",
              "149  MultinomialNB  full_text  ...      0.632193     0.572826\n",
              "150  MultinomialNB  full_text  ...      0.633319     0.572229\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df[results_df.TopKFeatures == 9000].sort_values(by='TestAccuracy', ascending=False).head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ewXpY6eG-aIx",
        "outputId": "d1422f6b-056d-4012-bf94-8c8aa529a18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>By</th>\n",
              "      <th>Preprocessed</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Ngram</th>\n",
              "      <th>TopKFeatures</th>\n",
              "      <th>TrainAccuracy</th>\n",
              "      <th>TestAccuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>9000</td>\n",
              "      <td>0.624065</td>\n",
              "      <td>0.570984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>9000</td>\n",
              "      <td>0.614543</td>\n",
              "      <td>0.559682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>9000</td>\n",
              "      <td>0.600795</td>\n",
              "      <td>0.555401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>full_text</td>\n",
              "      <td>1</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>9000</td>\n",
              "      <td>0.601779</td>\n",
              "      <td>0.554081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>headline</td>\n",
              "      <td>0</td>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>9000</td>\n",
              "      <td>0.603067</td>\n",
              "      <td>0.546912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Classifier         By  ... TrainAccuracy TestAccuracy\n",
              "145  MultinomialNB  full_text  ...      0.624065     0.570984\n",
              "188  MultinomialNB  full_text  ...      0.614543     0.559682\n",
              "155  MultinomialNB  full_text  ...      0.600795     0.555401\n",
              "198  MultinomialNB  full_text  ...      0.601779     0.554081\n",
              "105  MultinomialNB   headline  ...      0.603067     0.546912\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv('/content/drive/MyDrive/SDLC/news_analysis_project/resultsMB.csv')"
      ],
      "metadata": {
        "id": "hjiqo6Ko6qy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "classification_MB_for_all.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOJjYPhqUzk/xokVPYmyLL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}